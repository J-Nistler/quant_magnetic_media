---
title: "A Quantitative Approach to the Status of the Magnetic Media Crisis: From Hoping to Knowing"
author:
    - "Sarah Nguyen"
    - "Jared Nistler"
    - "Darach Miller"
tags: 
    - archives management
    - digitization
    - preservation
    - magnetic media
    - audio/visual media
abstract: |
    This is a quantitative study on the status of magnetic media collections.
    Data collected from forty-nine archive institutions, across the United 
    States and Canada, reveals the degree institutions are at risk in losing 
    historical and cultural magnetic records due to the lack of bandwidth in 
    digitizing collections, substandard environmental conditions, and the rapid
    deterioration rate of magnetic carriers. From a ten-question survey, data 
    reflects archivists managing magnetic media collections are not confident
    in their assessments of the once-ubiquitous materials. Numbers reveal 
    cognitive dissonance from clear discrepancies between quantities of format
    type compared to archivists’ self-reflection on preservation practice and 
    estimated digitization rates before obsolescence. The majority expressed 
    confidence in digitizing 75% or more of their collection, but calculating 
    that against actual digitization rates left more magnetic items 
    undigitized. The data also displays visible trend lines between carrier 
    type risk-level and the institutions holding similar quantities of each 
    format type. These patterns have the potential to assist with the challenge 
    of the medium’s limited lifespan as digitization and training hubs can be 
    concentrated near those institutions with similar format types. In a race against    
    the clock, archives are limited by funds and time as they attempt to preserve 
    valuable media before it degrades into unreadability. Data from this study
    will offer numbers to support institutions and archivists to obtain funding
    and prepare for the digitization to preservation processes before twenty 
    years pass and the magnetic media content is just a sticky memory. Read the rest 
    of this poster and/or visit our GitHub repository for reproducible data and more 
    details: [https://github.com/darachm/magnets_how_do_they_work](https://github.com/darachm/magnets_how_do_they_work)
---

```{r set_global_knit_options,echo=F,message=F,error=T}
knitr::opts_chunk$set(echo=F,message=F,error=T,warning=F)
```


# Intro, etc.

- what role does magnetic media have in our history/culture/hearts/minds/whatever?
- what is it?
- how degrade?
- why do a survey? to prioritize investment in training, documentation, staff, and digitization cores, or whatever y'all think is appropriate

# Methods

<!-- this is commented out
    Do not start things with tabs or 4+ spaces
    Markdown interprets that as code
    -->

This study involved mixed methodologies to answering the research question:
*What is the preservation status of magnetic media collections in academic* 
*libraries and archives, and to what degree are they endangered by degradation*
*and obsolescence?* From a questionnaire fulfilled by a sample of academic
libraries, quantitative data was gathered on collection size, format composition,
and digitization percentage to evaluate the current state of magnetic media
collections. Along with quantitative data, qualitative data was collected through
interviews on preservation management strategies to evaluate institutions’
responses to the magnetic media crisis.

The questionnaire was the primary data collection tool. Most, if not all,
academic institutions maintain records of the items within their collections,
and more often than not, they also track the formats of those items.
If an institution does not track this sort of data, it is an indication that
the institution does not have a comprehensive preservation management plan
prepared to properly address the magnetic media crisis. 

The first portion of the questionnaire asked for numerical values pertaining to
the amount and breakdown of magnetic media the institution holds as well as the
number of content hours that magnetic media contains. The second portion of the
questionnaire asked the institution about current preservation management
strategies in place, and how prepared they felt they were to deal with the
degradation and obsolescence of magnetic media.

The survey was created and hosted through the online platform SurveyMonkey and
disseminated through various electronic channels. These included SAA, ALA, and
AMIA listservs, Twitter, and emails sent to individual contacts. Email messages 
were adapted depending on the profession/personal relationships we had with the 
individual librarians and archivists. The questionnaire was initially circulated 
to all listservs on the night of November 7th and closed on November 21, 2018—a 
total of two full weeks. Throughout the two weeks in which the survey was open, 
individual and institutional reference emails were messaged for continual outreach. 
Once the questionnaire closed, data was cleaned and processed using OpenRefine and 
Google Sheets. R was used to create visualizations and additional data analysis after 
initial findings warranted a deeper evaluation.

# Response
- 9 of the 49 survey participants were comfortable in report accurate numbers when asked how many items held in their collections. This is problematic because the first step to preservation is evaluation (Paton 1998).
- 39 respondents represented an academic library
- 100% VHS & S-VHS in their collection was reported by one institution
- 1,551,273 total magnetic media items were reported to the questionnaire

# Results

```{r load_libraries}
library(tidyverse)
library(ggrepel)
library(egg)
library(ComplexHeatmap)
library(circlize)
```

```{r read_data_risks,cache=T}
raw_datar <- read_csv("survey_data_2019.csv" ,
    col_names=c(
        "Key","State","InstitutionType","TotalItems",
        "StorageConditions",
        "Unstructured_StorageHistory",
        "Unstructured_CompletionEstimate",
        "PercentDigitizedBeforeUnplayable",
        "PracticeSelfAssesment",
        "Percentage_Open Reel Video","Percentage_U-Matic","Percentage_Betamax",
        "Percentage_VHS & S-VHS","Percentage_Betacam & Betacam SP",
        "Percentage_Video 8 & Hi8","Percentage_D2","Percentage_D3",
        "Percentage_DVCAM","Percentage_MiniDV","Percentage_DVCPro",
        "Percentage_Digital 8","Percentage_Open Reel Audio",
        "Percentage_Compact Cassette","Percentage_Microcassette",
        "Percentage_DAT","Percentage_DTRS","Percentage_F-1","Percentage_DCC",
        "Percentage_8-Track","Percentage_Other"),
    skip=1
    ) %>%
    mutate(PercentDigitizedBeforeUnplayable=sub("%","",
            PercentDigitizedBeforeUnplayable)
        )
all_responses <- raw_datar

risk_factors <- read_tsv("risk_assesment.tsv") %>%
    mutate(Risk=factor(Risk,
            levels=c("Low","Moderate","High","Very High","Extremely High")
        )   ) 

tdatar <- all_responses %>%
    gather(Format,Percentage,starts_with("Percentage_")) %>%
    mutate(Percentage=as.numeric(sub("%","",Percentage))) %>%
    mutate(EstItemCount=TotalItems*Percentage/100) %>%
    mutate(FormatName=sub("Percentage_","",Format)) %>% 
    left_join(risk_factors%>%rename(FormatName=Format),by="FormatName")

```


We received ``r nrow(all_responses)`` responses. 


## Respondents by Institution Types

```{r responses_by_instutition_type,cache=T}
all_responses %>%
    {
    ggplot(.)+theme_bw()+
    aes(x=InstitutionType)+
    geom_bar()+
    scale_x_discrete(limits=names(sort(table(.$InstitutionType),decreasing=T)))+
    geom_label(aes(label=..count..,y=..count..),stat="count")+
    xlab("Institution type")+
    ylab("Responses")
    }
```

This research question specifically identified academic libraries as the main
focus, but other archival institutions have enthusiastically participated in
our survey. 

Despite a chunk of participants being non-academic libraries, the
research scope did not change and data from these other institutions are not
included in the final analysis. 

``r sum(all_responses$InstitutionType!="Academic")``
of these are not "Academic"

Shouldn't we include all of these? What's the difference?

However, the data trends are interesting and
can be applied to other institutions, there may be an opportunity for further
research.


## Distribution of Institution Facilities Environmental Conditions

** INCLUDE WITH ANOTHER GRAPH **
``r sum(is.na(all_responses$StorageConditions))`` didn't respond

```{r responses_by_storage_conditions,cache=T,fig.height=7}
all_responses %>%
    filter(!is.na(StorageConditions)) %>%
    {
    ggplot(.)+theme_bw()+
    aes(x=StorageConditions)+
    geom_bar()+
    scale_x_discrete(limits=c(
            "Archival (vacuum sealed items, cold storage, etc.)",
            "Temperature/Humidity controlled",
            "Room temperature",
            "Uncomfortable for human",
            "Actively harmful (dirty, hot, humid, etc.)"
            )
        )+
    geom_label(aes(label=..count..,y=..count..),stat="count")+
    theme(axis.text.x=element_text(angle=90))+
    xlab("")+
    ylab("Responses")
    }
```

Each questionnaire participant was asked to self-grade the environmental
conditions of the infrastructure which the magnetic media items are stored
within. The different environmental archival levels are based on the Video
Preservation Fact Sheet from AMIA.26 While the majority of the participants
boast to maintain “temperature/humidity controlled” for decent preservation of
magnetic media, the lack of “actively harmful” and “uncomfortable for humans”
environments is a huge indicator that the survey participants are
self-selecting. Given the number of institutions who are unable to account for
the number of items in their collection, this graph shows the study is missing
input from the “lone ranger archivists.”


## Distribution of Institutional Self-Reflection on A/V Digitization Practices

This graph of self-reflection on digitization practices must be taken with a
grain of salt since it is considering the judgment of the archivist managing
the collection itself. This is their job, and it is less likely for someone to
openly and truthfully speak poorly of their place of employment practices, even
if they are answering anonymously. On the other hand, it is encouraging to see
a positive-skewed bell curve, showing hope and potential in institutions
investment into A/V digitization practices.


```{r responses_by_self_reflection,cache=T,fig.height=7}
all_responses %>%
    filter(!is.na(PracticeSelfAssesment)) %>%
    {
    ggplot(.)+theme_bw()+
    aes(x=PracticeSelfAssesment)+
    geom_bar()+
    scale_x_discrete(limits=c(
            "Excellent",
            "Above Average",
            "Average",
            "Below Average",
            "Poor"
            )
        )+
    geom_label(aes(label=..count..,y=..count..),stat="count")+
    theme(axis.text.x=element_text(angle=90))+
    xlab("")+
    ylab("Responses")
    }
```

Let's compare them.

```{r responses_self_versus_storage,cache=T,fig.height=5}
all_responses %>%
    filter(!is.na(PracticeSelfAssesment)) %>%
    filter(!is.na(StorageConditions)) %>%
    {
    ggplot(.)+theme_bw()+
    aes(x=PracticeSelfAssesment,y=StorageConditions)+
    stat_bin2d(geom="point",aes(size=..count..),shape=15)+
    guides(fill=F)+
    scale_x_discrete(limits=c(
            "Excellent",
            "Above Average",
            "Average",
            "Below Average",
            "Poor"
            )
        )+
    scale_y_discrete(limits=c(
            "Archival (vacuum sealed items, cold storage, etc.)",
            "Temperature/Humidity controlled",
            "Room temperature",
            "Uncomfortable for human",
            "Actively harmful (dirty, hot, humid, etc.)"
            )
        )+
    scale_size("Responses")+
    theme(axis.text.x=element_text(angle=90))+
    xlab("Self-assessment of archival skillz")+
    ylab("Self-assessment of storage conditions")
    }
```

point types in R
http://www.sthda.com/english/wiki/r-plot-pch-symbols-the-different-point-shapes-available-in-r


## Institutional Estimate of the Percentage of Magnetic Media that will be Digitized before Estimated to be Unplayable And Environmental Conditions

Of the thirty-six respondents who chose to estimate how much magnetic material
they would be able to digitize, eight—nearly a quarter—were confident they
would process every item in their collection. However, almost as many
institutions expressed doubt that they would digitize even a quarter of their
collections before decay made their tapes unplayable. From a cursory
examination, there does not appear to be a strict correlation between the size
of the collection and the estimated digitization rate. Indiana University
Bloomington, with 226,911 items, is confident they will digitize 99% of their
holdings, while Wartburg College is bearish about the prospects for their
15,308 items, estimating they will only digitize 10%. Table 2: Respondent
Institutions’ Digitization Progress Rates lists institutions’ current progress
rate, calculated by their yearly digitization rate as a percentage of their
total collection.

```{r percent_completion,cache=T}
all_responses %>%
    filter(!is.na(PercentDigitizedBeforeUnplayable)) %>%
    {
    ggplot(.)+theme_bw()+
    aes(x=as.numeric(PercentDigitizedBeforeUnplayable))+
    stat_bin(binwidth=10,geom="bar")+
    xlab("Self-assessed estimate of complete digitization\nbefore media is unplayable (binned into tenths)")+
    ylab("Responses per bin (width")+
    coord_flip()
    }
```

**POSTER-1**
TO DO: 2 histograms side-by-side
```{r storage_conditions_and_completion,cache=T,fig.height=7}
g_storage_vs_complete <- all_responses %>%
    filter(!is.na(StorageConditions)) %>%
    filter(!is.na(PercentDigitizedBeforeUnplayable)) %>%
    {
    ggplot(.)+
    theme_article()+scale_fill_distiller(palette="Spectral")+
    aes(x=as.numeric(PercentDigitizedBeforeUnplayable),y=StorageConditions)+
    scale_y_discrete(limits=c(
            "Archival (vacuum sealed items, cold storage, etc.)",
            "Temperature/Humidity controlled",
            "Room temperature",
            "Uncomfortable for human",
            "Actively harmful (dirty, hot, humid, etc.)"
            )
        )+
    stat_bin2d(binwidth=c(10,1))+
    xlab("Self-assessed estimate of complete digitization\nbefore media is unplayable")+
    ylab("Responses per bin")+
    scale_x_continuous(breaks=seq(0,100,10))
    }
g_storage_vs_complete

g_storage <- all_responses %>%
    filter(!is.na(StorageConditions)) %>%
    {
    ggplot(.)+theme_article()+
    aes(x=StorageConditions)+
    scale_x_discrete(limits=c(
            "Archival (vacuum sealed items, cold storage, etc.)",
            "Temperature/Humidity controlled",
            "Room temperature",
            "Uncomfortable for human",
            "Actively harmful (dirty, hot, humid, etc.)"
            ),
            labels=c(
            "Archival\n(vacuum sealed items,\ncold storage, etc.)",
            "Temperature/Humidity\ncontrolled",
            "Room temperature",
            "Uncomfortable\nfor humans",
            "Actively harmful\n(dirty, hot, humid, etc.)"
            )
        )+
    geom_bar(fill="grey40",color="black")+
    #geom_label(aes(label=..count..,y=..count..),stat="count")+
    scale_y_continuous(breaks=seq(0,40,5))+
    theme(axis.text.x=element_text(angle=90))+
    xlab("")+
    ylab("Responses")
    }
g_complete <- all_responses %>%
    filter(!is.na(PercentDigitizedBeforeUnplayable)) %>%
    {
    ggplot(.)+theme_article()+
    aes(x=as.numeric(PercentDigitizedBeforeUnplayable))+
    stat_bin(binwidth=10,center=5,geom="bar",fill="grey40",color="black")+
    xlab("Self-assessed estimate of complete\ndigitization before media is unplayable")+
    ylab("Responses")+
    scale_x_continuous(breaks=seq(0,100,10))+
    scale_y_continuous(breaks=seq(0,10,1))
    }
g_both <- ggarrange(g_storage,g_complete,nrow=1,labels=c("A","B"))
g_both

ggsave("storageConditions_and_completionEstimate.svg",g_both,width=6,height=4)
ggsave("storageConditions_and_completionEstimate.png",g_both,width=6,height=4)
```


## Total items of each format type and their obsolescence risk factor

**POSTER-2**
```{r format_counts_divided_x_by_risk,cache=T,fig.height=7}
g <- tdatar %>% 
    group_by(FormatName,Risk) %>%
    summarize(EstTotal=sum(EstItemCount,na.rm=T)) %>%
    filter(!is.na(Risk)) %>%
    filter(EstTotal>0) %>%
    ggplot()+
    theme_bw()+
    aes(x=Risk,y=EstTotal,label=FormatName)+
    geom_text_repel(box.padding=1,segment.color="grey60")+
    theme(axis.text.x=element_text(angle=90))+
    ylab("Total estimated items, across survey")+
    xlab("Risk Estimate")
g

g+geom_dotplot(binaxis="y",stackdir="center",binwidth=3e3)

g+geom_dotplot(binaxis="y",stackdir="center",binwidth=0.05)+
    scale_y_log10(labels=function(x){formatC(x,big.mark=",",format="d")},
        breaks=c(500+0.5,1e3,2e3,5e3+0.5,1e4,2e4,5e4+1,1e5,2e5))

ggsave("risk_and_totals_log.png",g+
    geom_dotplot(binaxis="y",stackdir="center",binwidth=0.05)+
    scale_y_log10(labels=function(x){formatC(x,big.mark=",",format="d")},
        breaks=c(500+0.5,1e3,2e3,5e3+0.5,1e4,2e4,5e4+1,1e5,2e5)),
    width=6,height=6)
ggsave("risk_and_totals_log.svg",g+
    geom_dotplot(binaxis="y",stackdir="center",binwidth=0.05)+
    scale_y_log10(labels=function(x){formatC(x,big.mark=",",format="d")},
        breaks=c(500+0.5,1e3,2e3,5e3+0.5,1e4,2e4,5e4+1,1e5,2e5)),
    width=6,height=6)

ggsave("risk_and_totals.png", g+
    scale_y_continuous(labels=function(x){formatC(x,big.mark=",",format="d")},
        breaks=seq(0,2e5,2e4),limits=c(-2e4,NA))+
        geom_dotplot(binaxis="y",stackdir="center",binwidth=3e3),
    width=6,height=6)
ggsave("risk_and_totals.svg", g+
    scale_y_continuous(labels=function(x){formatC(x,big.mark=",",format="d")},
        breaks=seq(0,2e5,2e4),limits=c(-2e4,NA))+
        geom_dotplot(binaxis="y",stackdir="center",binwidth=3e3) ,
    width=6,height=6)

```

## Estimated Number of Each Format

**POSTER-3**

```{r total_numbers_of_items_each_format_dist,cache=T}

g <- tdatar %>% 
    {
    ggplot(.)+
    theme_bw()+
    aes(x=FormatName,y=EstItemCount)+
    geom_boxplot(outlier.alpha=0,color="grey50")+
    geom_dotplot(binaxis="y",stackdir="center",dotsize=1.0,alpha=1.0,binwidth=0.05)+
    scale_y_log10(labels=function(x){formatC(x,big.mark=",",format="d")})+
    scale_x_discrete(
        limits=group_by(.,FormatName)%>%
            summarize(z=sum(EstItemCount,na.rm=T))%>%
            arrange(-z)%>%pull(FormatName)
        )+
    theme(axis.text.x=element_text(angle=90))+
    ylab("Each respondent's estimated items per format")+
    xlab("")
    }
g
ggsave("items_per_respondent.png",g,width=8,height=6)
ggsave("items_per_respondent.svg",g,width=8,height=6)

```

This box plot mirrors what we've seen in that there are noticeable high
quantities of VHS and open reel audio, but this makes it more apparent where
there are instituions holding an skewed amount of a format type within their
collection. It's clear that there are a lot of data points in VHS. Nearly all
participating institutions have at least one VHS tape. On the other hand, there
are only about four or five archives that need to deal with Digital 8.

These are calculatinos based on the percentages given and the absolute total of instiutions' collections shared.



## Magnetic Media Collections by Region and Climate

** POSTER-4**

Instead, we will focus on the variability of institutions collections considering the geographic region, the region's climate properties (e.g. humidity, temp, etc.), and the reported environmental conditions of the archive itself. We might consider the quantity of each format according to region, but not sure how that will work or what
results that will give us. 

label = # of institutions responding  
type of color = major climate risk/threat
intensity of color = amount of total items estimated based on survey

We received respondents from all different climates. There is a bias because certain regions/states have a lot more data. 


## Final Overview Heat Map

** POSTER-5**
This heat map illustrates an aggregation of the above charts and graphs. The
hierarchical clustering shows how each format is related or unrelated
considering the factors of obsolesence risk and quantity held within
participating archives' collections. At the top of the chart, there are two
major goups: (1) VHS, open reel audio, and compact cassettes, and (2) all other
formats. This distinction is from the quantity that instutions hold, in that
group 1 is more likely to have a higher quantity than group 2. From quantity
and risk factor, there is a noticeable relationship with Betacam and u-matic.
This suggests that if an archive carries of one of these format types, they are
likely to also have the latter in their collection. This further leads to the
idea that training or programming for Betacam and U-matic together could be an
efficient approach to dealing with those collections.

TO DO:  
* Order y-axis of instutions by estimated percent of completion
* new color scale

```{r 2nd_heatmap_counts,fig.height=9,fig.width=9,cache=T}
library(gplots)

heatmap_datar_counts <- tdatar %>% 
    filter(EstItemCount>0) %>%
    select(Key,State,InstitutionType,TotalItems,
        PercentDigitizedBeforeUnplayable,FormatName,EstItemCount) %>%
    spread(FormatName,EstItemCount,fill=0) %>%
    arrange(-as.numeric(PercentDigitizedBeforeUnplayable))
heatmap_datar_counts%>%pull(PercentDigitizedBeforeUnplayable)

counts_matrix <- as.matrix(log10(heatmap_datar_counts[,-c(1,2,3,4,5)]+1))

#risk_palette <- 
#    rev(colorRampPalette(brewer.pal(n=9,name="Spectral"))(
#        length(levels(risk_factors$Risk))
#    ))[
#        tibble(Format=colnames(heatmap_datar_counts)[
#                6:ncol(heatmap_datar_counts)]
#            )%>%    
#            left_join(risk_factors,by="Format")%>%pull(Risk)
#        ] 

# Thanks colorbrewer2 website!
colorz <- setNames(c('#ffffb2','#fecc5c','#fd8d3c','#f03b20','#bd0026'),
        levels(risk_factors$Risk))
risk_palette <- colorz[
        tibble(Format=colnames(heatmap_datar_counts)[
                6:ncol(heatmap_datar_counts)]
            )%>%    
            left_join(risk_factors,by="Format")%>%pull(Risk)
        ] 
k <- data.frame(fill=colorz[levels(risk_factors$Risk)],y=levels(risk_factors$Risk)) %>%
    ggplot()+theme_classic()+
    aes(fill=y,x=1,y=y)+
    scale_fill_manual("Risk",values=colorz)+
    scale_y_discrete(limits=levels(risk_factors$Risk))+
    guides(fill=F)+
    geom_tile()+
    theme(axis.text.x=element_blank(),axis.ticks=element_blank(),
        axis.line=element_blank())+
    ylab("")+xlab("")
k
ggsave("heatmap_key.png",k,width=3,height=2)

tickfunc <- function() {
            breaks <- 10^seq(1,5,0.1)
            which_ones <- c(11,21,31,41)
            return(list(
                at=parent.frame()$scale01(log10(breaks[which_ones])),
                labels=formatC(breaks[which_ones],big.mark=",",format="d")
                ))
           }


svg("magnetic_heatmap_ordered_by_chance_completion_at_top.svg",width=8,height=8)
heatmap.2(counts_matrix,
    key.xlab="Estimated Items",
    col=colorRampPalette(brewer.pal(n=9,name="PuBuGn"))(100),
    ColSideColors=risk_palette,
    margins=c(08,2),
    labRow="",
    srtCol=45,
    density.info="none",
    trace="none",
    dendrogram="col",
    Rowv=F,
    reorderfun=function(d, w) rev(reorder(d, w, agglo.FUN = mean)),
    ylab="Respondent, ordered by estimated completion",
    key.xtickfun=tickfunc
    )
dev.off()

svg("magnetic_heatmap_clustered_rows.svg",width=8,height=8)
heatmap.2(counts_matrix,
    key.xlab="Estimated Items",
    col=colorRampPalette(brewer.pal(n=9,name="PuBuGn"))(100),
    ColSideColors=risk_palette,
    margins=c(08,2),
    labRow="",
    srtCol=45,
    density.info="none",
    trace="none",
    dendrogram="both",
    reorderfun=function(d, w) rev(reorder(d, w, agglo.FUN = mean)),
    ylab="Respondent",
    key.xtickfun=tickfunc
    )
dev.off()


library(RColorBrewer)


```


Organized by total counts of the items - how important is it overall?
```{r heatmap_counts,fig.height=9,fig.width=9,cache=T}
library(seriation)

seriation_of_matrix <- seriate(as.matrix(log10(heatmap_datar_counts[,-c(1,2,3,4)]+1)))
#, method = "BEA_TSP")

heatmap_datar_counts <- tdatar %>% 
    filter(EstItemCount>0) %>%
    select(Key,State,InstitutionType,TotalItems,FormatName,EstItemCount) %>%
    spread(FormatName,EstItemCount,fill=0)

counts_valz <- log10(unlist(heatmap_datar_counts[,-c(1,2,3,4)])+1)

col_ann <- risk_factors %>% rename(FormatName=Format) %>% as.data.frame()
rownames(col_ann) <- col_ann[[1]]
col_ann <- col_ann %>% select(-FormatName) %>% rename(`Format Risk`=Risk)

risk_annotation <- HeatmapAnnotation(
    `Format Risk`=col_ann$`Format Risk`,
    col=list(`Format Risk`=c(
            `Extremely High`="#7b3294",`Very High`="#c2a5cf",
            `High`="#a6dba0",`Moderate`="#008837"
    )   )   )
the_heatmap <- Heatmap(
    log10(heatmap_datar_counts[,-c(1,2,3,4)]+1),
    top_annotation=risk_annotation,
    col=colorRamp2(
        c(min(counts_valz),median(counts_valz),max(counts_valz)),
        c("#ffffff", "#fefefe", "#000000")
        ),
    heatmap_legend_param = list(
        title="Item counts", 
        at=log10(c(10+1,1000+1,1e4+1,5e4+1)),
        labels=c(10,1000,1e4,5e4),
        legend_height = unit(6, "cm"),
        heatmap_legend_side="bottom"
        ),
    row_order=get_order(seriation_of_matrix,1),
    column_order=get_order(seriation_of_matrix,2)
    )
ht_list <- the_heatmap 
g <- draw(ht_list, heatmap_legend_side = "right", annotation_legend_side = "right")
```

** DELETE **
Organized by fraction of the collection that is each format - 
how important is it overall?
```{r heatmap_frac,cache=T,fig.height=9,fig.width=9}
heatmap_datar_frac <- tdatar %>% 
    filter(EstItemCount>0) %>%
    select(Key,State,InstitutionType,TotalItems,FormatName,Percentage) %>%
    mutate(Fraction=Percentage/100)%>%
    select(-Percentage) %>%
    spread(FormatName,Fraction,fill=0)

#TotalItems,StorageConditions,PercentDigitizedBeforeUnplayable,PracticeSelfAssessment,

frac_valz <- unlist(heatmap_datar_frac[,-c(1,2,3,4)])

col_ann <- risk_factors %>% rename(FormatName=Format) %>% as.data.frame()
rownames(col_ann) <- col_ann[[1]]
col_ann <- col_ann %>% select(-FormatName) %>% rename(`Format Risk`=Risk)

risk_annotation <- HeatmapAnnotation(
    `Format Risk`=col_ann$`Format Risk`,
    col=list(
        `Format Risk`=c(
            `Extremely High`="#7b3294",`Very High`="#c2a5cf",
            `High`="#a6dba0",`Moderate`="#008837"
            )
    )   )
the_heatmap <- Heatmap(
    log10(heatmap_datar_frac[,-c(1,2,3,4)]+.001),
    top_annotation=risk_annotation,
    col=colorRamp2(
        log10(c(min(frac_valz),median(frac_valz),max(frac_valz))+.001),
        c("#ffffff", "#fefefe", "#000000")
        ),
    heatmap_legend_param = list(
        title="Fraction of\ncollection", 
        at=log10(c(0,0.05,0.1,0.30)+0.001),
        labels=c("1%","5%","10%","30%"),
        legend_height = unit(6, "cm"),
        heatmap_legend_side="bottom"
        )
    )
ht_list <- the_heatmap 
g <- draw(ht_list, heatmap_legend_side = "right", annotation_legend_side = "right")



```


correlation matrix

# Conclusions

While the data comes from a limited pool of academic archives and therefore cannot speak for all archives, the data can still serve to indicate what may be expected. Additional research addressing the preservation status of magnetic media collections in academic libraries, and to what degree are they endangered, could only make a stronger case for funding proposals. However, even without further research, it is imperative to report that archivists must begin by conducting assessments and evaluations of their collections in order to allocate resources to digitize their magnetic media collections. This is a crucial first step that needs to happen now, not later during the institution’s five-year plan. Moreover, this study illustrates that many institutions have not taken this first step.

# Future Opportunities

# References

# Acknowledgements

Many thanks to: our LIS 570 collaborators, Brian Click and Michael Kuster, who helped with the literature review, method design, and co-writing the original paper. Paul J. Weiss, LIS 570 instructor, who inspired and guided us to use this project to engage and contribute to the larger archives community. All survey respondents, interviewees, and archive listervs who welcomed our research to the discussion forums. Thank you SAA for accepted our research to the graduate student poster presentation. 

# Supplemental Analyses

Because how often do you get to see the axes of variation amongst human 
institutions? Be they collections or formats both are dope !

```{r,cache=T}
pca_datar <- tdatar %>% select(Key,TotalItems,FormatName,EstItemCount) %>%
    spread(FormatName,EstItemCount,fill=0)

matrix_by_inst <- as.matrix(pca_datar[,-c(1,2)])
rownames(matrix_by_inst) <- pca_datar[,1][[1]]
cluster_inst <- hclust(dist(scale(matrix_by_inst))) 
matrix_by_media <- t(as.matrix(pca_datar[,-c(1,2)]))
cluster_media <- hclust(dist(scale(matrix_by_media)))
```

## PCA of media format

What major patterns of variation amongst formats are seen, with respect to their
inventory in different institutions?
The ways in which some factors are similar to each other and then distinct to others.Groupings of how formats are distributed differently. 
 

```{r pca_media,cache=T}
pca_media <- prcomp(t(matrix_by_media[apply(matrix_by_media,1,sum)>0,]),center=T,scale=T)

media_pca_plot <- pca_media$rotation %>% 
    {bind_cols(tibble(Format=rownames(.)),as.tibble(.))} %>%
    select(Format,PC1,PC2,PC3,PC4,PC5,PC6) %>% 
    ggplot()+theme_bw()+
    aes(label=Format)+
    geom_point()+
    geom_label_repel()
media_pca_plot + aes(x=PC1,y=PC2)
```

This is where you say there's a big main trend of the things in the top right
are a group, things more to the left are not, this is probably generally 
popularity.

Stuff on bottom is the first distinct cluster.

```{r pca_media2,cache=T}
media_pca_plot + aes(x=PC3,y=PC4)
```

Betacam and Other are special, MiniDV in it's own special place


## PCA of institutions

What major patterns of variation amongst formats are seen, with respect to their
inventory in different institutions?

For completeness, these are all plots.

Note plot 2 (3 vs 4) shows how museums and historical societies are way 
different, probably have a lot of Other formats.

More surveys needed

```{r pca_inst,cache=T}
pca_inst <- prcomp(t(matrix_by_inst[apply(matrix_by_inst,1,sum)>0,] ),center=T,scale=T)
percent_varz <- signif(pca_inst$sdev / sum(pca_inst$sdev) * 100,3)

filtered_mbi <- matrix_by_inst[apply(matrix_by_inst,1,sum)>0,]

pdatar <- pca_inst$rotation %>% 
    {bind_cols(tibble(Key=rownames(.)),as.tibble(.))} %>%
    select(Key,PC1,PC2,PC3,PC4,PC5,PC6) %>% 
    left_join(all_responses%>%mutate(Key=as.character(Key)),by="Key") 

inst_pca_plot <- pdatar %>%
    ggplot()+theme_bw()+
    aes(label=Key)+
    geom_point()+
    geom_label_repel()
pc12 <- inst_pca_plot+aes(x=PC1,y=PC2)+
    xlab(paste0("PC1 ",percent_varz[1],"% variance"))+
    ylab(paste0("PC2 ",percent_varz[2],"% variance"))
pc34 <- inst_pca_plot + aes(x=PC3,y=PC4)+
    xlab(paste0("PC3 ",percent_varz[3],"% variance"))+
    ylab(paste0("PC4 ",percent_varz[4],"% variance"))
pc56 <- inst_pca_plot + aes(x=PC5,y=PC6)+
    xlab(paste0("PC5 ",percent_varz[5],"% variance"))+
    ylab(paste0("PC6 ",percent_varz[6],"% variance"))

pc12+aes(fill=InstitutionType)
pc34+aes(fill=InstitutionType)
pc56+aes(fill=InstitutionType)
```

Huh what's on each of these axis? Why are museums different than academic 
archives?

Here's a plot of the correlation of each format with each axis.
Labelled are one-test significant for pearson correlation.

```{r pca_dig_in_pearson,cache=T}
z <- apply(pca_inst$rotation[,1:6],2,
    function(x){
       lapply(apply(filtered_mbi,2,cor.test,x,method="pearson"),
            function(y){
                data.frame(pval=y$p.value,est=y$estimate)
            })
    })
rez <- data.frame(PC=NA,Format=NA,pval=NA,est=NA)
for (i in names(z)) {
    for (j in names(z[i][[1]])) {
        rez <- rbind(rez,cbind(data.frame(PC=i,Format=j),z[i][[1]][j][[1]]))
    }
}
rez <- rez[-1,]
# god that's ugly, I forgot how to do a for loop for a bit there
ggplot(rez)+theme_bw()+
    aes(label=Format,x=-log10(pval),y=est)+
    facet_wrap(~PC)+
    geom_point()+
    geom_label_repel(data=subset(rez,pval<0.05))
```


And if we replot some of those back on the PCA plots:
Bridge the gap between institution types. Consider GLAM practices but also this shows the instittution type does hold different assets, which means different needs. 

```{r replot_pcas,cache=T}
pc14 <- inst_pca_plot+aes(x=PC1,y=PC4,fill=as.numeric(sub("%","",Percentage_Other)))+
    xlab(paste0("PC1 ",percent_varz[1],"% variance"))+
    ylab(paste0("PC4 ",percent_varz[4],"% variance"))+
    scale_fill_distiller("Other",palette="Spectral",na.value="lightblue")
pc14

pc23 <- inst_pca_plot + aes(x=PC2,y=PC3)+
    xlab(paste0("PC2 ",percent_varz[2],"% variance"))+
    ylab(paste0("PC3 ",percent_varz[3],"% variance"))

pc23+aes(fill=as.numeric(sub("%","",`Percentage_Other`)))+
    scale_fill_distiller("Other",palette="Spectral",na.value="lightblue")

pc23+aes(fill=0+
        as.numeric(sub("%","",`Percentage_U-Matic`))+
        as.numeric(sub("%","",`Percentage_Betacam & Betacam SP`))
        )+
    scale_fill_distiller("Umatic or Betacam",palette="Spectral",na.value="lightblue")

```

And for spearman
```{r pca_dig_in_spearman,cache=T}
z <- apply(pca_inst$rotation[,1:6],2,
    function(x){
       lapply(apply(filtered_mbi,2,cor.test,x,method="spearman"),
            function(y){
                data.frame(pval=y$p.value,est=y$estimate)
            })
    })
rez <- data.frame(PC=NA,Format=NA,pval=NA,est=NA)
for (i in names(z)) {
    for (j in names(z[i][[1]])) {
        rez <- rbind(rez,cbind(data.frame(PC=i,Format=j),z[i][[1]][j][[1]]))
    }
}
rez <- rez[-1,]
# god that's ugly, I forgot how to do a for loop for a bit there
ggplot(rez)+theme_bw()+
    aes(label=Format,x=-log10(pval),y=est)+
    facet_wrap(~PC)+
    geom_point()+
    geom_label_repel(data=subset(rez,pval<0.05))
```


```{r reigon,cache=T,echo=F,eval=F}
pc12+aes(fill=c(
    `Wisconsin`="Central",
    `Washington D.C.`="East",
    `Massachusetts`="East",
    `New York`="East",
    `California`="West",
    `Iowa`="Central",
    `Hawaii`="Out",
    `Pennsylvania`="East",
    `Oregon`="West",
    `Colorado`="West",
    `Delaware`="East",
    `Idaho`="West",
    `Indiana`="Central",
    `Maryland`="East",
    `Washington`="West",
    `Louisiana`="South",
    `New Mexico`="West",
    `Ohio`="Central",
    `British Columbia`="West",
    `Texas`="South",
    `Alaska`="Out",
    `Florida`="South",
    `Missouri`="South",
    `Nebraska`="Central",
    `Utah`="West",
    `Virginia`="East",
    `Wyoming`="West",
    `Kentucky`="East"
    )[State])
```



```{r pheatmap,echo=F,eval=F}
##library(pheatmap)
##row_ann <- data.frame(
##    Collection=str_c("C_",as.character(rownames(matrix_by_inst)[cluster_inst$order]))
##    )
##rownames(row_ann) <- as.character(row_ann[[1]])
##
##col_ann <- data.frame(Format=rownames(matrix_by_media)[cluster_media$order]) %>%
##    left_join(totals_and_risks,by="Format") %>% select(-variable) %>%
##    rename(`Total Items`=Total,`Format Risk`=Risk) %>%
##    select(-`Total Items`)
##rownames(col_ann) <- col_ann[[1]]
##col_ann <- col_ann %>% select(-Format)
##count_palette <- c("#FFFFFF",
##    colorRampPalette((RColorBrewer::brewer.pal(n=7,name="YlGnBu")))(99)
##    )
##
##g <- pheatmap( log10(heatmap_datar[,-c(1,2)]+400),
##    color=count_palette,
##    correlation_distance_rows="pearson",
##    correlation_distance_cols="pearson",
##    legend_breaks=log10(c(10,100,1000,3000,1e4,2.5e4,5e4)),
##    legend_labels=c(10,100,1000,3000,1e4,2.5e4,5e4),
##    cluster_rows=cluster_inst,
##    cluster_cols=cluster_media,
##    show_rownames=F,show_colnames=T,
##    #annotation_row=row_ann,
##    annotation_col=col_ann,
##    annotation_legend=T)
##g
```
